name: Scrape Jobs
on:
  schedule:
    - cron: "0 */2 * * *"   # every 2 hours
  workflow_dispatch: {}      # allow manual run
permissions:
  contents: write
jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Run scraper
        env:
          GOOGLE_SHEET_ID: ${{ secrets.GOOGLE_SHEET_ID }}
          GOOGLE_SHEET_TAB: ${{ secrets.GOOGLE_SHEET_TAB }}
          GOOGLE_SERVICE_ACCOUNT_JSON: ${{ secrets.GOOGLE_SERVICE_ACCOUNT_JSON }}
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
        run: python main.py
      - name: Commit results
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add output/*.csv || true
          git commit -m "Update jobs $(date -u +'%Y-%m-%d %H:%M:%S') UTC" || echo "No changes"
          git push
